{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93a762d0",
   "metadata": {},
   "source": [
    "\n",
    "# Major topics in chains are:\n",
    "# 1. Chat Messages: Human input → AI/LLM → Output\n",
    "# 2. Chat Models: LLM Models → Use chat models in graph nodes\n",
    "# 3. Binding Tools: Connecting external tools/functions to LLM models for enhanced functionality\n",
    "# 4. How do we execute tool calls from the LLM in graph nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a400d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='The capital of France is Paris.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 14, 'total_tokens': 21, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_07871e2ad8', 'finish_reason': 'stop', 'logprobs': None} id='run-1a5c5255-0726-4e8c-b31f-1daca50d1dfb-0' usage_metadata={'input_tokens': 14, 'output_tokens': 7, 'total_tokens': 21, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16fdacb",
   "metadata": {},
   "source": [
    "# How to use chat messages as our graph state \n",
    "\n",
    "# In LangGraph, we can use chat messages as the state that flows between nodes\n",
    "# This allows us to build conversational AI systems where each node can:\n",
    "# 1. Read previous messages in the conversation\n",
    "# 2. Add new messages to the conversation history\n",
    "# 3. Pass the updated conversation to the next node\n",
    "\n",
    "# The state typically contains a list of messages with roles like:\n",
    "# - \"human\": Messages from the user\n",
    "# - \"assistant\": Messages from the AI/LLM\n",
    "# - \"system\": System instructions or context\n",
    "# - \"tool\": Results from tool executions\n",
    "\n",
    "# This approach enables building complex conversational flows where:\n",
    "# - Context is preserved across multiple interactions\n",
    "# - Different nodes can handle different types of responses\n",
    "# - Tool calls and their results are tracked in the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4836f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: LLMModel\n",
      "\n",
      "How can I help you\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: Bharath\n",
      "\n",
      "I want to know about the weather in Tokyo\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: LLMModel\n",
      "\n",
      "The weather in Tokyo is sunny\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage,HumanMessage\n",
    "from pprint import pprint\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "#llm=ChatOpenAI(model=\"gpt-4o\",temperature=0)\n",
    "\n",
    "messages=[AIMessage(content=f\"How can I help you\",name=\"LLMModel\")]\n",
    "messages.append(HumanMessage(content=\"I want to know about the weather in Tokyo\",name=\"Bharath\"))\n",
    "messages.append(AIMessage(content=f\"The weather in Tokyo is sunny\",name=\"LLMModel\"))\n",
    "\n",
    "for message in messages:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d9f85e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of France is Paris.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 17, 'total_tokens': 25, 'completion_time': 0.00616336, 'prompt_time': 0.002613809, 'queue_time': 0.06782283500000001, 'total_time': 0.008777169}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_8b7c3a83f7', 'finish_reason': 'stop', 'logprobs': None}, id='run-2ec0e295-1acb-4058-abfb-3b6908605c9f-0', usage_metadata={'input_tokens': 17, 'output_tokens': 8, 'total_tokens': 25})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm=ChatGroq(model=\"llama3-8b-8192\",temperature=0)\n",
    "llm.invoke(\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f22b023",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655c9ec0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e52c83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5051ab19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6d9c65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Course_Requirement",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
